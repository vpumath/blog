[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi there, welcome to my math blog! I will write about topics that I want either to (re)learn, I am curious about or I find fun. My style will be expository writing, but I will add some mathematical details and terms to the text to make things somewhat rigorous (sometimes I can go full technical details mode). I hope that this provides a general overview of the topics for larger audience and an opportunity to dive into more advanced mathematics for the readers that get interested about more advanced terms, concepts and theorems.\nI write this blog as a hobby, so this blog ain’t peer reviewed. I have limited amount of energy and time to proofread and double check calculations and theorems. Check details and reasoning also yourself and from another sources. I do my best to catch every mistake before posting, but some errors can slip through despite my effort.\nHopefully you have enjoyable time while reading the blog! ^^"
  },
  {
    "objectID": "posts/EV_doesnt_always_tell_whole_story/index.html",
    "href": "posts/EV_doesnt_always_tell_whole_story/index.html",
    "title": "Expected value does not always tell the whole story",
    "section": "",
    "text": "In poker, there is a rule of thumb that you should play plus EV (Expected Value) lines and avoid negative EV lines and indeed it is important to play more plus EV lines than negative EV lines in the long run. However, expected value is a mathematical “measurement” that has its limitations and can be misleading sometimes. It would be really weird if just one number would be able to provide perfect information for decision making.\nThere are examples of cases where making plus EV decisions would be absolutely insane. Those cases are quite simple, but it can be instructive to see how one would construct such scenarios. Sometimes mathematics is all about building examples where things doesn’t work as one would imagine.\n\nBasics of expected value\nHow one could end up with inventing expected value: Let’s start by considering a scenario that has two outcomes: The outcome \\(1\\) has probability \\(p_1\\) and a result \\(r_1.\\) The outcome \\(2\\) has probability \\(p_2\\) and a result \\(r_2.\\) How could we evaluate the scenario? Let start by two observations:\n\nIf the result \\(r_1\\) increases, then the evaluation should increase. The opposite should also be true.\nIf the probability of \\(p_1\\) increases, the effect (weight) of the result should increase and if the probability goes to zero, the effect of that result should vanish.\n\nBy multiplying \\(p_1\\) and \\(r_1\\) we get an object \\(p_1 r_1\\) that has above desired behaviour with respect of the first outcome. We can do this as well for the other outcome as well and get \\(p_2 r_2\\). By summing these two, we get some way to evaluate the result \\(R\\) of the scenario: \\[\\mathbb{E}(R) = p_1 r_1 + p_2 r_2.\\] This is called expected value of \\(R\\). This can be generalized to the case when we have several outcomes. Let’s us have a scenario that has \\(N\\) outcomes and outcome \\(k\\) has probabilty \\(p_k\\) and a result \\(r_k\\), then the expected value of the result \\(R\\) of the scenario is \\[ \\mathbb{E}(R) = \\sum_{k=1}^N p_k r_k.\\] Each component of that sum has the desired behavior that we listed above. Furthermore, the expected value \\(\\mathbb{E}(R)\\) as a whole has the property that if some probabilty \\(p_k = 1\\), then \\(\\mathbb{E}(R) = r_k\\) which is the behaviour that we would want from the evaluation (If we know that event \\(k\\) is going to happen for sure, then the evaluation should be exactly the result \\(r_k\\)). Thus, the expected value \\(\\mathbb{E}(R)\\) has a sensible behaviour. EV can be generalized to the case when there are (countably) infinitely many discrete cases and to the case when the random variable (result) is continuous, vector-valued or something even wilder.\n\n\n\n\n\n\nNoteAn elementary property of expected value in the discrete finite case\n\n\n\nExpected value is always between the smallest and largest value of the result (random variable). Constructing a proof (mathematical argument) for this is a great exercise if you haven’t made many proofs in your life. This property is also something that makes sense and is something that we would like to have.\n\n\nNow, we can give scenarios some kind of evaluation about what to expect. One could think if EV is a good number in the context of scenario, then the scenario would be good, but this isn’t always the case.\n\n\nHow could we make an example where EV behaves unintuively?\nIn mathematics, one way to break things is to choose really large or really small numbers. We need to do both to produce an example. Let’s return to the scenario where we had two outcomes and set \\(r_1 = -10\\) (An entry fee of 10 units of money to a game which is lost if one loses). Let’s choose the prize of the game to be absolutely bonkers \\(r_2 = 10^{20}\\) units of money and the probability of winning to be \\(p_2=10^{-10}\\). Then the EV is\n\\[ \\mathbb{E}(R) = (1-10^{-10}) \\cdot (-10) + 10^{-10} \\cdot 10^{20} =  10^{10} -(1-10^{-10}) \\cdot 10  \\approx 10^{10}. \\]\nEV of approximately \\(10^{10}\\) units of money is a decent amount money in any currency even in this current cost of living crisis. That is a good EV in my books and we could tinker it to be big as we want. But the problem is that probability of winning is so small that one would never win in that game, on average.\nOut of the curiousness, let’s calculate how many tries it would take to win in that game, on average: The probability that we would win at try \\(k\\) is \\(\\mathbb{P}(Q=k) = (1-p)^{k-1}p\\) (we lose \\(k-1\\) times and then win). Now we take a mathematical shortcut and use known results instead of calculating by hand: The random variable \\(Q\\) has a geometric distribution which has expected value of \\(\\mathbb{E}(Q) = \\frac{1}{p}\\). So it would take \\(\\frac{1}{10^{-10}}=10^{10}\\) tries, on average. A person that lives 100 years has about \\(3.1536 \\cdot 10^9\\) seconds in their lives and that wouldn’t be enough if they played the game every second, on average.\n\n\n\n\n\n\nNotesmall differences in luck can make huge difference in life.\n\n\n\nFrom that math above: Let’s say that you have \\(1\\%\\) chance to get a job, you need to make 100 quality applications, on average. If you can improve that by just \\(1\\%\\), the average amount of number of applications needed decreases by 50. We can deduce that when things are hard, even small improvements can make a huge difference.\nOne can also see that even small differences in general luck between humans can lead to drastically different experience of life. Let’s say that person \\(1\\) has general luck of \\(1\\%\\) and person \\(2\\) has general luck of \\(5\\%\\), the difference in luck is only \\(4\\%\\), but person \\(2\\) has to make \\(80\\%\\) less tries, on average.\nOf course, these observations are only relevant in the situations when the probabilities are small.\n\n\nI know that it is a bit funny to say beware of EV and then use the EV of geometric distribution to show why you need to be wary about EVs. The phrase “on average” has been doing the most of the heavy lifting during this blog post. What do we mean by “on average” and how we could determine how attainable the EV is?\n\n\nThe central limit theorem\nWhen we run same scenario \\(n\\) times in a way where the runs are independent of each others, then we can study the average result, \\(A_n\\), of the results:\n\\[ A_n  = \\frac{\\sum_{k=1}^n R_k}{n} \\]\nwhere the \\(R_k\\) is the result of the \\(k\\)-th run and every \\(R_k\\) will have the same distribution \\(R\\). Now there exists a very famous theorem that connects the average result, \\(A_n\\), to the expected value \\(\\mathbb{E}(R)\\).\nThe central limit theorem says the following: Assume that \\(R, R_1,R_2, \\dots, R_n\\) are identially independently distributed random variables with finite expected value \\(\\mathbb{E}(R)\\) and finite variance \\(\\mathrm{Var}(R) = \\sigma^2\\). Then as the \\(n\\) grows, the distribution of \\(\\frac{A_n - \\mathbb{E}(R)}{\\frac{\\sigma}{\\sqrt{n}}}\\) converges in distribution to the normal distribution \\(\\mathcal{N}(0,1)\\) and the same in the limit notation\n\\[ \\lim_{n \\to \\infty} \\frac{A_n - \\mathbb{E}(R)}{\\frac{\\sigma}{\\sqrt{n}}} \\xrightarrow{d} \\mathcal{N}(0, 1). \\]\nHere \\(\\sigma^2\\) is the variance of \\(R\\). Before we continue our journey to definition of variance, “couple” words about what this means. Basically, this means that when \\(n\\) grows, we can approximate probability calculations about the average \\(A_n\\) with the normal distribution \\(\\mathcal{N}(\\mathbb{E}(R), \\frac{\\sigma^2}{n})\\) as the approximation.\n\n\n\n\n\n\nCautionAn instructive silly goose moment No. 1 (a bit advanced exercise)\n\n\n\n\n\nI tried to find/make a formulation of the central limit theorem that would say something like this\n\\[ \\lim_{n \\to \\infty} A_n \\xrightarrow{d} \\mathcal{N}(\\mathbb{E}(R), \\frac{\\sigma^2}{n}) \\]\nas it would show better what happens to \\(A_n\\), but then I realized that I was a really silly goose. Why is finding a formulation like this impossible?\n\n\n\nMoreover, if the probability density function of \\(R\\) for example is bounded, we can say that probability density function of \\(\\frac{A_n - \\mathbb{E}(R)}{\\frac{\\sigma}{\\sqrt{n}}}\\) converges pointwisely to the probability density function of the normal distribution \\(\\mathcal{N}(0,1)\\) (the probability density function of \\(A_n\\) will look like normal distribution at some point). This isn’t true for every random variable that fulfills the central limit theorem conditions, so we need to be delicate how we interpret the central limit theorem. Local limit theorems give conditions when the probability density function of \\(\\frac{A_n - \\mathbb{E}(R)}{\\frac{\\sigma}{\\sqrt{n}}}\\) converges pointwisely to the normal distribution \\(\\mathcal{N}(0,1)\\). Additional information is available for example from here, here or from here. (Not an expert on local limit theorems, so take my words with a grain of salt)\nIf there were terms or stuff that were unfamiliar or confusing, you can skip them and focus on “when n grows, the probability distribution of the average \\(A_n\\) starts to behave like it would be normal distribution \\(\\mathcal{N}(\\mathbb{E}(R), \\frac{\\sigma^2}{n})\\)”. The exact way to handle technical details is a much longer story and we are not delving into it here. The most important observation is that the variance will decrease when \\(n\\) grows. I think that the following interactive visualization is the best way to demonstrate how normal distribution look and how variance \\(\\frac{\\sigma^2}{n}\\) affect it.\n\nfunction square(x){\n\n  return x*x;\n}\n\nfunction range(a, b, h) {\n  if (h &lt;= 0) throw new Error('Step size h must be positive')\n  // Ensure we move in the right direction even if a &gt; b\n  const forward = a &lt;= b\n  const step = forward ? h : -h\n  const result = []\n\n  // Use a tolerance to avoid floating‑point drift (e.g., 0.1 + 0.2 ≠ 0.3 exactly)\n  const eps = Math.abs(step) / 1e12\n\n  for (let v = a; forward ? v &lt;= b + eps : v &gt;= b - eps; v += step) {\n    // Round to a reasonable number of decimal places to hide FP artefacts\n    result.push(Number(v.toFixed(12)))\n  }\n\n  return result\n}\n\nx = range(-100,100,0.1);\n\ny = x.map(x=&gt;normalPDF(x,mu,variance));\n\n\n\n\nfunction normalPDF(x, mu, var_) {\n  const sigma = Math.sqrt(var_);\n  const coefficient = 1 / (sigma * Math.sqrt(2 * Math.PI));\n  const exponent = -Math.pow(x - mu, 2) / (2 * var_);\n  return coefficient * Math.exp(exponent);\n}\n\n\nPlot.plot({\n  marks: [\n    Plot.line(\n      x.map((d, i) =&gt; ({x: d, y: y[i]})),\n      {x: \"x\", y: \"y\"}\n    )\n  ],\n  x: {label: \"X-axis\"},\n  y: {label: \"Y-axis\"}\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof mu = Inputs.range([-30, 30], {label: \"the expected value \", step: 1});\nviewof variance = Inputs.range([0.1, 1000], {label: \"Variance\", step: 0.1});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSo we can say that in the long run, the average result \\(A_n\\) will converge to the expected value \\(\\mathbb{E}(R)\\), i.e.\n\\[ \\lim_{n \\to \\infty} A_n \\rightarrow \\mathbb{E}(R).\\]\nThis holds in sense of “convergence in probability” and “converges almost surely” and these kind of limit theorems are variants of law of large numbers theorems.\nIn general, there isn’t an exact way to tell how long it takes before the average converges to the expected value, but qualitatively we can say that the larger variance is, the larger probability to deviate from the expected value is at the beginning. The same is true for the question “when the normal distribution approximation is good enough?”.\n\n\nSo, what is variance?\nI think that the central limit theorem shows why variance is an important quantity. The variance, \\(\\mathrm{Var}(R)\\), of random result (variable) \\(R\\) is defined as follows\n\\[ \\mathrm{Var}(R) = \\mathbb{E}[(R-\\mathbb{E}(R))^2]. \\]\nLet us write this for the case when we have finite number results \\(r_1,r_2,\\dots, r_N\\) with probabilities \\(p_1,p_2,\\dots p_N\\) respectively:\n\\[ \\mathrm{Var}(R) = \\sum_{k=1}^N p_k(r_k - \\mathbb{E}(R))^2. \\]\nIn a way, variance studies how far away every potential result is from expected value and the distance is weighted by the probability of the result and these quantities are summed together. There are multiple potential choices for “distance function”. For example, one could use \\(|R-\\mathbb{E}(R)|\\) as well, but the square function produces the most useful properties for the variance.\nLet’s calculate the variance in our unintuitive case (using the approximated EV, \\(\\mathbb{E}(R) \\approx 10^{10}\\))\n\\[ \\mathrm{Var}(R) \\approx (1-10^{-10})\\cdot (-10-10^{10})^2 + 10^{-10} \\cdot (10^{20} - 10^{10})^2 \\approx 10^{30}. \\] For some odd reason, I would guess that with this variance the convergence to expected value might take a while.\n\n\n\n\n\n\nNoteYou can also use Chebyshev’s inequality to estimate what is the probability of getting results that are at least certain distance from the expected value\n\n\n\nThe Chebyshev’s inequality says that for a random variable \\(R\\) with \\(\\mathbb{E}(|R|) &lt; \\infty\\) and finite variance the following inequality holds\n\\[ \\mathbb{P}(|R-\\mathbb{E}(R)| \\geq a ) \\leq \\frac{\\mathrm{Var}(R)}{a^2}.\\]\nThis gives a crude way to estimate probabilities, but this gives an upper bound for the probabilities without making assumptions about convergence or other stuff. Also, it is good enough for proving weak law of large numbers.\n\n\nWhat could we learn here? If someone says to you that here is an opportunity with a great EV, the question “what is the variance of the said opportunity?” would be a really good question to figure out. The next good question would be “What is the 95% confidence interval of the said opportunity?”, but that question is another story for another time."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Expected value does not always tell the whole story\n\n\n\nProbability\n\n\n\n\n\n\n\n\n\nOct 28, 2025\n\n\nVeli-Pekka Uusluoto\n\n\n\n\n\nNo matching items"
  }
]