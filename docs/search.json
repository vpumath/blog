[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi there, welcome to my math blog! I will write about topics that I want either to (re)learn, I am curious about or I find fun. My style will be expository writing, but I will add some mathematical details and terms to the text to make things somewhat rigorous (sometimes I can go full technical details mode). I hope that this provides a general overview of the topics for larger audience and an opportunity to dive into more advanced mathematics for the readers that get interested about more advanced terms, concepts and theorems.\nI write this blog as a hobby, so this blog ain’t peer reviewed. I have limited amount of energy and time to proofread and double check calculations and theorems. Check details and reasoning also yourself and from another sources. I do my best to catch every mistake before posting, but some errors can slip through despite my effort.\nHopefully you have enjoyable time while reading the blog! ^^"
  },
  {
    "objectID": "posts/EV_doesnt_always_tell_whole_story/index.html",
    "href": "posts/EV_doesnt_always_tell_whole_story/index.html",
    "title": "Expected value does not always tell the whole story",
    "section": "",
    "text": "In poker, there is a rule of thumb that you should play plus EV (Expected Value) lines and avoid negative EV lines and indeed it is important to play more plus EV lines than negative EV lines in the long run. However, expected value is a mathematical “measurement” that has its limitations and can be misleading sometimes. It would be really weird if just one number would be able to provide perfect information for decision making.\nThere are examples of cases where making plus EV decisions would be absolutely insane. Those cases are quite simple, but it can be instructive to see how one would construct such scenarios. Sometimes mathematics is all about building examples where things doesn’t work as one would imagine.\n\nBasics of expected value\nHow one could end up with inventing expected value: Let’s start by considering a scenario that has two outcomes: The outcome \\(1\\) has probability \\(p_1\\) and a result \\(r_1.\\) The outcome \\(2\\) has probability \\(p_2\\) and a result \\(r_2.\\) How could we evaluate the scenario? Let start by two observations:\n\nIf the result \\(r_1\\) increases, then the evaluation should increase. The opposite should also be true.\nIf the probability of \\(p_1\\) increases, the effect (weight) of the result should increase and if the probability goes to zero, the effect of that result should vanish.\n\nBy multiplying \\(p_1\\) and \\(r_1\\) we get an object \\(p_1 r_1\\) that has above desired behaviour with respect of the first outcome. We can do this as well for the other outcome as well and get \\(p_2 r_2\\). By summing these two, we get some way to evaluate the result \\(R\\) of the scenario: \\[\\mathbb{E}(R) = p_1 r_1 + p_2 r_2.\\] This is called expected value of \\(R\\). This can be generalized to the case when we have several outcomes. Let’s us have a scenario that has \\(N\\) outcomes and outcome \\(k\\) has probabilty \\(p_k\\) and a result \\(r_k\\), then the expected value of the result \\(R\\) of the scenario is \\[ \\mathbb{E}(R) = \\sum_{k=1}^N p_k r_k.\\] Each component of that sum has the desired behavior that we listed above. Furthermore, the expected value \\(\\mathbb{E}(R)\\) as a whole has the property that if some probabilty \\(p_k = 1\\), then \\(\\mathbb{E}(R) = r_k\\) which is the behaviour that we would want from the evaluation (If we know that event \\(k\\) is going to happen for sure, then the evaluation should be exactly the result \\(r_k\\)). Thus, the expected value \\(\\mathbb{E}(R)\\) has a sensible behaviour. EV can be generalized to the case when there are (countably) infinitely many discrete cases and to the case when the random variable (result) is continuous, vector-valued or something even wilder.\n\n\n\n\n\n\nNoteAn elementary property of expected value in the discrete finite case\n\n\n\nExpected value is always between the smallest and largest value of the result (random variable). Constructing a proof (mathematical argument) for this is a great exercise if you haven’t made many proofs in your life. This property is also something that makes sense and is something that we would like to have.\n\n\nNow, we can give scenarios some kind of evaluation about what to expect. One could think if EV is a good number in the context of scenario, then the scenario would be good, but this isn’t always the case.\n\n\nHow could we make an example where EV behaves unintuively?\nIn mathematics, one way to break things is to choose really large or really small numbers. We need to do both to produce an example. Let’s return to the scenario where we had two outcomes and set \\(r_1 = -10\\) (An entry fee of 10 units of money to a game which is lost if one loses). Let’s choose the prize of the game to be absolutely bonkers \\(r_2 = 10^{20}\\) units of money and the probability of winning to be \\(p_2=10^{-10}\\). Then the EV is\n\\[ \\mathbb{E}(R) = (1-10^{-10}) \\cdot (-10) + 10^{-10} \\cdot 10^{20} =  10^{10} -(1-10^{-10}) \\cdot 10  \\approx 10^{10}. \\]\nEV of approximately \\(10^{10}\\) units of money is a decent amount money in any currency even in this current cost of living crisis. That is a good EV in my books and we could tinker it to be big as we want. But the problem is that probability of winning is so small that one would never win in that game, on average.\nOut of the curiousness, let’s calculate how many tries it would take to win in that game, on average: The probability that we would win at try \\(k\\) is \\(\\mathbb{P}(Q=k) = (1-p)^{k-1}p\\) (we lose \\(k-1\\) times and then win). Now we take a mathematical shortcut and use known results instead of calculating by hand: The random variable \\(Q\\) has a geometric distribution which has expected value of \\(\\mathbb{E}(Q) = \\frac{1}{p}\\). So it would take \\(\\frac{1}{10^{-10}}=10^{10}\\) tries, on average. A person that lives 100 years has about \\(3.1536 \\cdot 10^9\\) seconds in their lives and that wouldn’t be enough if they played the game every second, on average.\n\n\n\n\n\n\nNotesmall differences in luck can make huge difference in life.\n\n\n\nFrom that math above: Let’s say that you have \\(1\\%\\) chance to get a job, you need to make 100 quality applications, on average. If you can improve that by just \\(1\\%\\), the average amount of number of applications needed decreases by 50. We can deduce that when things are hard, even small improvements can make a huge difference.\nOne can also see that even small differences in general luck between humans can lead to drastically different experience of life. Let’s say that person \\(1\\) has general luck of \\(1\\%\\) and person \\(2\\) has general luck of \\(5\\%\\), the difference in luck is only \\(4\\%\\), but person \\(2\\) has to make \\(80\\%\\) less tries, on average.\nOf course, these observations are only relevant in the situations when the probabilities are small.\n\n\nI know that it is a bit funny to say beware of EV and then use the EV of geometric distribution to show why you need to be wary about EVs. The phrase “on average” has been doing the most of the heavy lifting during this blog post. What do we mean by “on average” and how we could determine how attainable the EV is?\n\n\nThe central limit theorem\nWhen we run same scenario \\(n\\) times in a way where the runs are independent of each others, then we can study the average result, \\(A_n\\), of the results:\n\\[ A_n  = \\frac{\\sum_{k=1}^n R_k}{n} \\]\nwhere the \\(R_k\\) is the result of the \\(k\\)-th run and every \\(R_k\\) will have the same distribution \\(R\\). Now there exists a very famous theorem that connects the average result, \\(A_n\\), to the expected value \\(\\mathbb{E}(R)\\).\nThe central limit theorem says the following: Assume that \\(R, R_1,R_2, \\dots, R_n\\) are identially independently distributed random variables with finite expected value \\(\\mathbb{E}(R)\\) and finite variance \\(\\mathrm{Var}(R) = \\sigma^2\\). Then as the \\(n\\) grows, the distribution of \\(\\frac{A_n - \\mathbb{E}(R)}{\\frac{\\sigma}{\\sqrt{n}}}\\) converges in distribution to the normal distribution \\(\\mathcal{N}(0,1)\\) and the same in the limit notation\n\\[ \\lim_{n \\to \\infty} \\frac{A_n - \\mathbb{E}(R)}{\\frac{\\sigma}{\\sqrt{n}}} \\xrightarrow{d} \\mathcal{N}(0, 1). \\]\nHere \\(\\sigma^2\\) is the variance of \\(R\\). Before we continue our journey to definition of variance, “couple” words about what this means. Basically, this means that when \\(n\\) grows, we can approximate probability calculations about the average \\(A_n\\) with the normal distribution \\(\\mathcal{N}(\\mathbb{E}(R), \\frac{\\sigma^2}{n})\\) as the approximation.\n\n\n\n\n\n\nCautionAn instructive silly goose moment No. 1 (a bit advanced exercise)\n\n\n\n\n\nI tried to find/make a formulation of the central limit theorem that would say something like this\n\\[ \\lim_{n \\to \\infty} A_n \\xrightarrow{d} \\mathcal{N}(\\mathbb{E}(R), \\frac{\\sigma^2}{n}) \\]\nas it would show better what happens to \\(A_n\\), but then I realized that I was a really silly goose. Why is finding a formulation like this impossible?\n\n\n\nMoreover, if the probability density function of \\(R\\) for example is bounded, we can say that probability density function of \\(\\frac{A_n - \\mathbb{E}(R)}{\\frac{\\sigma}{\\sqrt{n}}}\\) converges pointwisely to the probability density function of the normal distribution \\(\\mathcal{N}(0,1)\\) (the probability density function of \\(A_n\\) will look like normal distribution at some point). This isn’t true for every random variable that fulfills the central limit theorem conditions, so we need to be delicate how we interpret the central limit theorem. Local limit theorems give conditions when the probability density function of \\(\\frac{A_n - \\mathbb{E}(R)}{\\frac{\\sigma}{\\sqrt{n}}}\\) converges pointwisely to the normal distribution \\(\\mathcal{N}(0,1)\\). Additional information is available for example from here, here or from here. (Not an expert on local limit theorems, so take my words with a grain of salt)\nIf there were terms or stuff that were unfamiliar or confusing, you can skip them and focus on “when n grows, the probability distribution of the average \\(A_n\\) starts to behave like it would be normal distribution \\(\\mathcal{N}(\\mathbb{E}(R), \\frac{\\sigma^2}{n})\\)”. The exact way to handle technical details is a much longer story and we are not delving into it here. The most important observation is that the variance will decrease when \\(n\\) grows. I think that the following interactive visualization is the best way to demonstrate how normal distribution look and how variance \\(\\frac{\\sigma^2}{n}\\) affect it.\n\nfunction square(x){\n\n  return x*x;\n}\n\nfunction range(a, b, h) {\n  if (h &lt;= 0) throw new Error('Step size h must be positive')\n  // Ensure we move in the right direction even if a &gt; b\n  const forward = a &lt;= b\n  const step = forward ? h : -h\n  const result = []\n\n  // Use a tolerance to avoid floating‑point drift (e.g., 0.1 + 0.2 ≠ 0.3 exactly)\n  const eps = Math.abs(step) / 1e12\n\n  for (let v = a; forward ? v &lt;= b + eps : v &gt;= b - eps; v += step) {\n    // Round to a reasonable number of decimal places to hide FP artefacts\n    result.push(Number(v.toFixed(12)))\n  }\n\n  return result\n}\n\nx = range(-100,100,0.1);\n\ny = x.map(x=&gt;normalPDF(x,mu,variance));\n\n\n\n\nfunction normalPDF(x, mu, var_) {\n  const sigma = Math.sqrt(var_);\n  const coefficient = 1 / (sigma * Math.sqrt(2 * Math.PI));\n  const exponent = -Math.pow(x - mu, 2) / (2 * var_);\n  return coefficient * Math.exp(exponent);\n}\n\n\nPlot.plot({\n  marks: [\n    Plot.line(\n      x.map((d, i) =&gt; ({x: d, y: y[i]})),\n      {x: \"x\", y: \"y\"}\n    )\n  ],\n  x: {label: \"X-axis\"},\n  y: {label: \"Y-axis\"}\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof mu = Inputs.range([-30, 30], {label: \"the expected value \", step: 1});\nviewof variance = Inputs.range([0.1, 1000], {label: \"Variance\", step: 0.1});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSo we can say that in the long run, the average result \\(A_n\\) will converge to the expected value \\(\\mathbb{E}(R)\\), i.e.\n\\[ \\lim_{n \\to \\infty} A_n \\rightarrow \\mathbb{E}(R).\\]\nThis holds in sense of “convergence in probability” and “converges almost surely” and these kind of limit theorems are variants of law of large numbers theorems.\nIn general, there isn’t an exact way to tell how long it takes before the average converges to the expected value, but qualitatively we can say that the larger variance is, the larger probability to deviate from the expected value is at the beginning. The same is true for the question “when the normal distribution approximation is good enough?”.\n\n\nSo, what is variance?\nI think that the central limit theorem shows why variance is an important quantity. The variance, \\(\\mathrm{Var}(R)\\), of random result (variable) \\(R\\) is defined as follows\n\\[ \\mathrm{Var}(R) = \\mathbb{E}[(R-\\mathbb{E}(R))^2]. \\]\nLet us write this for the case when we have finite number results \\(r_1,r_2,\\dots, r_N\\) with probabilities \\(p_1,p_2,\\dots p_N\\) respectively:\n\\[ \\mathrm{Var}(R) = \\sum_{k=1}^N p_k(r_k - \\mathbb{E}(R))^2. \\]\nIn a way, variance studies how far away every potential result is from expected value and the distance is weighted by the probability of the result and these quantities are summed together. There are multiple potential choices for “distance function”. For example, one could use \\(|R-\\mathbb{E}(R)|\\) as well, but the square function produces the most useful properties for the variance.\nLet’s calculate the variance in our unintuitive case (using the approximated EV, \\(\\mathbb{E}(R) \\approx 10^{10}\\))\n\\[ \\mathrm{Var}(R) \\approx (1-10^{-10})\\cdot (-10-10^{10})^2 + 10^{-10} \\cdot (10^{20} - 10^{10})^2 \\approx 10^{30}. \\] For some odd reason, I would guess that with this variance the convergence to expected value might take a while.\n\n\n\n\n\n\nNoteYou can also use Chebyshev’s inequality to estimate what is the probability of getting results that are at least certain distance from the expected value\n\n\n\nThe Chebyshev’s inequality says that for a random variable \\(R\\) with \\(\\mathbb{E}(|R|) &lt; \\infty\\) and finite variance the following inequality holds\n\\[ \\mathbb{P}(|R-\\mathbb{E}(R)| \\geq a ) \\leq \\frac{\\mathrm{Var}(R)}{a^2}.\\]\nThis gives a crude way to estimate probabilities, but this gives an upper bound for the probabilities without making assumptions about convergence or other stuff. Also, it is good enough for proving weak law of large numbers.\n\n\nWhat could we learn here? If someone says to you that here is an opportunity with a great EV, the question “what is the variance of the said opportunity?” would be a really good question to figure out. The next good question would be “What is the 95% confidence interval of the said opportunity?”, but that question is another story for another time."
  },
  {
    "objectID": "posts/Finding_multiple_mathematical_models_for_same_phenomenon_is_a_good_thing/index.html",
    "href": "posts/Finding_multiple_mathematical_models_for_same_phenomenon_is_a_good_thing/index.html",
    "title": "Finding multiple mathematical models for same phenomenon is a good thing",
    "section": "",
    "text": "Finding an unifying collection of equations and principles that would explain everything in the universe under single compatible framework would be a holy grail for physicists and mathematicians. With theory of everything, you could potentially predict everything which could be very useful. Let’s say that some day such theory is found. Are other models unneccesary after that? I would like to argue that knowing and finding other mathematical models is important even in that scenario (as it is useful to know/figure out multiple solutions for a problems and multiple proofs for a single theorem). I hope that with this I could show how to analyze mathematical models from human perspective: What would make mathematical models (or theories) easier or harder humans to learn/understand.\n\n“Mechanistical” model of a system.\nThere are many kind of mathematical models, but now I want discuss “mechanistical” models of dynamical systems. The following is one way to think about dynamical systems and the world: Mathematical model of dynamical system consist of environment/space \\(\\mathcal{E}\\), building blocks \\(\\mathcal{B}\\) and dynamics between building blocks \\(\\mathcal{D}\\) and a mathematical model of a system could be thought as a triple \\((\\mathcal{E},\\mathcal{B}, \\mathcal{D})\\). Additionally, when studying a system that evolve, the history of the system could be an important part of the model as it would describe why there are certain things in the system (this is one good idea in John H. Holland’s book Signals and boundaries).\nThe environment part of the model will describe the spatial/environmental aspects of a system and how we think that system interacts with outside world. For example, boundary conditions describes often how system interacts with outside world. Building blocks describe smallest parts of the system that we want to include to the model. For example building blocks of system might be particles, field quantities or agents. Dynamics of the system tells how we think that the building blocks of a system will interact with each other.\nMany different models can describe a system equivalently or nearly equivalently and there isn’t an unique model for a system. This can be seen by a thought experiment: Let’s have a model that describe system to a desired precision. If we have another model that has smaller building blocks than previous model and we can build the bigger building blocks from smaller ones, then the models would produce nearly equivalent results in the scope of the model that has bigger building blocks. (Assuming that both models produce accurate results and models are applied in the scale where they are precise).\nIn a way, we notice that some mathematical models form a hierarchial/nested structure. In mathematical modelling there is at least two questions: What is the smallest building block in the model and what part or pheomenon of a system we want to understand or be able to predict. Sometimes, we don’t need to understand or model every part of a system or what happens between events and sometimes we need to: If we want to predict where a golf ball lands after a swing, we don’t necessarily need to model the dynamics of atmosphere, but if we study where a frisbee lands, then we may need to, at least in some accuracy.\nThis is true also while writing mathematics and proofs. We select what axioms we take for granted, what theorems and properties we assume to be known and what objects are already defined. Sometimes unpacking a proof with details can add clarity as it makes mental steps smaller. Sometimes it only confuses the reader as the journey takes longer and is messier. The above characterization can be little bit non-exact. Let me try to somehow formulate and “quantify” what I mean.\n\n\nTradeoffs of mathematical models and human limits.\nIn every model, we have certain number of\n\nobjects or building blocks,\ndynamical laws and principles,\ncomputational steps (computational load).\n\nWhen we look from human perspective, humans need to be capable to\n\nremember,\nunderstand,\nbuild and\napply\n\nthe model at some level if they want to get the joy of understanding. One of the most limiting factors of humans is memory capabilities. If we want to achieve intellectually elegant model, finding a model that minimizes the amount of building blocks, dynamics and computational load of the model, would the best bet. Of course, without sacrificing the precision and the prediction capabilities of the model.\nIf we don’t care how enjoyable the model is and how much human understanding it provides about dynamical laws of the system, we can totally forget about minimizing the model since computer memory is cheap and we can go ham with it. For example, some AI models tend to be black box models (they work well, but we don’t know how and why they work).\nFor both, the selection of smallest building blocks determines the resolution of model: Often we can’t get results or understanding about phenomena or dynamics of a systems that are smaller than our smallest building block. If the building block are selected to be too small, achieving knowledge about much larger pheomena or dynamics may be computationally too demanding or slow even for the best computer.\nWhen we return to think about a model that gives a theory of everything. I would guess that its smallest building blocks would be really small and thus computing anything about human size phenomena would be infeasible. Therefore, we need to continue to develop and learn different mathematical models. When learning or studying something, changing what one takes to be smallest building blocks can be really enlightening and make the journey easier."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Finding multiple mathematical models for same phenomenon is a good thing\n\n\n\nMathematical modelling\n\n\n\n\n\n\n\n\n\nNov 4, 2025\n\n\nVeli-Pekka Uusluoto\n\n\n\n\n\n\n\n\n\n\n\n\nExpected value does not always tell the whole story\n\n\n\nProbability\n\n\n\n\n\n\n\n\n\nOct 28, 2025\n\n\nVeli-Pekka Uusluoto\n\n\n\n\n\nNo matching items"
  }
]